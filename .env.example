# API Configuration
API_HOST=127.0.0.1
API_PORT=7887

# Azure OpenAI Configuration
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your-api-key
AZURE_OPENAI_MODEL=gpt-4o-mini
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o-mini

# Embedding Configuration
EMBEDDING_DEVICE=cuda
EMBEDDING_BULK_BATCH_SIZE=32
EMBEDDING_MAX_CHUNK_SIZE=512

# Local Embedding Configuration
LOCAL_EMBEDDING_MODEL=intfloat/multilingual-e5-large
LOCAL_RERANK_MODEL=BAAI/bge-reranker-v2-m3

# Hugging Face Configuration
HUGGING_FACE_TOKEN=your-hf-token

# Reranking Configuration
RERANK_MODEL=mixedbread-ai/mxbai-rerank-base-v2
RERANK_DEVICE=auto
RERANK_MAX_LENGTH=
RERANK_MAX_CHUNK_SIZE=512

# Cache Directories
SENTENCE_TRANSFORMERS_HOME=data/models/sentence-transformers
HF_HOME=data/models/huggingface

# Vector Database Configuration
CHROMA_COLLECTION_NAME=workitems
CHROMA_DB_PATH=data/chroma_db

# Data Ingestion Configuration
USE_INCREMENTAL_SYNC=true

# Scheduler Configuration
SCHEDULER_ENABLED=false
SCHEDULER_INTERVAL_HOURS=6
SCHEDULED_INGESTION_TIME=02:00

# CORS Configuration
CORS_ALLOW_ORIGINS=*
CORS_ALLOW_CREDENTIALS=false

# Wiki Summarization Configuration (orbis only)
WIKI_MAX_INPUT_TOKENS_PER_CHUNK=15000
WIKI_OVERLAP_TOKENS=500
WIKI_CACHE_DURATION_HOURS=2400
WIKI_TARGET_OUTPUT_TOKENS_PER_PAGE=3000
WIKI_MAX_CONTENT_SIZE_MB=10
WIKI_CONTENT_SIZE_CHECK_ENABLED=true
WIKI_MAX_OUTPUT_TOKENS=20000
WIKI_DEBUG_LOGGING_ENABLED=true
WIKI_DEBUG_LOG_DIR=logs/wiki_summaries
WIKI_MODEL_CONTEXT_LIMIT=128000
WIKI_SAFE_OUTPUT_LIMIT=16000

# Optional Encryption Key (Fernet key for sensitive data at rest)
ENCRYPTION_KEY=
